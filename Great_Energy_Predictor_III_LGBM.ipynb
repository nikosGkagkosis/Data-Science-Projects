{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Forecasting Daily Electrical Energy Consumption with LightGBM\n",
        "\n",
        "This notebook demonstrates how to use Light Gradient Boosting Machine (LightGBM) to forecast the daily consumption of electrical energy."
      ],
      "metadata": {
        "id": "_8gs9mMpU5uU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mjMsNwYnjIOr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Donload and read the files from kaggle\n",
        "\n",
        "train= pd.read_csv('path')\n",
        "\n",
        "weather= pd.read_csv('path')\n",
        "\n",
        "building= pd.read_csv('path')"
      ],
      "metadata": {
        "id": "R4WbX-AfVjCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))"
      ],
      "metadata": {
        "id": "_x3DtzP-Q_0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA & FE"
      ],
      "metadata": {
        "id": "1TQa27anH_Y5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTS7QH-s0P0H"
      },
      "outputs": [],
      "source": [
        "print( \"train columns are :\",train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rdCqh5v8IDrT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS5J-ke_0qJp"
      },
      "outputs": [],
      "source": [
        "print(\"weather columns are :\",weather.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVnqTwNm00Ap"
      },
      "outputs": [],
      "source": [
        "print(\"building columns are :\", building.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NspkW1CIvqk8"
      },
      "outputs": [],
      "source": [
        "data = train.merge(building, on='building_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.merge(weather, on=['site_id', 'timestamp'], how='left')"
      ],
      "metadata": {
        "id": "FauCniNgCoYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "WqE0BbDpC2CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "0eTrbTYnD4dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For saving some memory\n",
        "del weather,building\n",
        "gc.collect();"
      ],
      "metadata": {
        "id": "b5yiTKu-DD0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "idZsdvT5DO8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save some memory"
      ],
      "metadata": {
        "id": "qBmkDjD3DkOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_types = {\n",
        "    \"building_id\": np.int16,\n",
        "    \"meter\": np.int8,\n",
        "    \"site_id\": np.int8,\n",
        "    \"primary_use\": \"category\",\n",
        "    \"square_feet\": np.int32,\n",
        "    \"year_built\": np.float16,       # better: Int16 if no fractions\n",
        "    \"floor_count\": np.float16,      # better: Int8/Int16 if integer counts\n",
        "    \"air_temperature\": np.float32,\n",
        "    \"cloud_coverage\": np.float16,   # better: Int8 if bounded counts\n",
        "    \"dew_temperature\": np.float32,\n",
        "    \"precip_depth_1_hr\": np.float16,\n",
        "    \"sea_level_pressure\": np.float32,\n",
        "    \"wind_direction\": np.float16,\n",
        "    \"wind_speed\": np.float32,\n",
        "    \"timestamp\": \"datetime64[ns]\"        # ✅ convert object → datetime\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "data=data.astype(d_types,copy=False)"
      ],
      "metadata": {
        "id": "CPblTZmLDqZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "RJXZTmtME0Xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Break_timestamp(df):\n",
        "  df['timestamp']= pd.to_datetime(df['timestamp'])\n",
        "  df['hour']= np.uint8(df['timestamp'].dt.hour)\n",
        "  df['dayofweek']= np.uint8(df['timestamp'].dt.dayofweek)\n",
        "  df['month']= np.uint8(df['timestamp'].dt.month)\n",
        "  df['dayofyear']= np.uint16(df['timestamp'].dt.dayofyear)\n",
        "  df['day']= np.uint16(df['timestamp'].dt.day)\n",
        "  df['year']= np.uint16(df['timestamp'].dt.year)\n",
        "  return df"
      ],
      "metadata": {
        "id": "jZOi7iZrGKiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Break_timestamp(data);\n",
        "data.columns"
      ],
      "metadata": {
        "id": "cYFiTZNqHh87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def missing_values(df):\n",
        "\n",
        "  missing_vals = df.isnull().sum() * 100 / len(df);\n",
        "  missing_vals_df=pd.DataFrame({\n",
        "\n",
        "      'Percentage of missing values':missing_vals\n",
        "  })\n",
        "  print(missing_vals_df)\n"
      ],
      "metadata": {
        "id": "YLGYo9S_IQTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values(data)"
      ],
      "metadata": {
        "id": "mBwkaWnSIix6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#zero_readings=data[data['meter_reading']==0].index\n",
        "#data.drop(zero_readings,inplace=True)\n",
        "\n",
        "data=data[data['meter_reading']!=0]"
      ],
      "metadata": {
        "id": "dx5i82xmODqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "_oPdB0c5Nr6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrBZqLBlmPbs"
      },
      "outputs": [],
      "source": [
        "data.drop(['year_built', 'floor_count'], axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smart fill (group mean) → keeps local/site/day/month context.\n",
        "If every row in a group is missing(no data for this group combination) → the group mean is NaN → nothing gets filled ❌\n",
        "\n",
        "Backup fill (global median) → guarantees no NaNs survive.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tmumf1qRWZFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nan_filler(df):\n",
        "  group=['site_id','day','month','year']\n",
        "  weather_columns= [\n",
        "        'air_temperature', 'dew_temperature', 'cloud_coverage',\n",
        "        'sea_level_pressure', 'precip_depth_1_hr',\n",
        "        'wind_direction', 'wind_speed'\n",
        "    ]\n",
        "\n",
        "  for col in weather_columns:\n",
        "  # Step 1: group mean fill\n",
        "    group_mean=df.groupby(group)[col].transform('mean')\n",
        "    df[col]=df[col].fillna(group_mean)\n",
        "\n",
        "  for col_2 in weather_columns:\n",
        "  # Step 2: fallback global median fill\n",
        "    df[col_2] = df[col_2].fillna(df[col_2].median())\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "iPNzgjd8Whe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_filler(data)"
      ],
      "metadata": {
        "id": "_NFB-JANdI5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values(data)"
      ],
      "metadata": {
        "id": "4D2xWP26ddjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_season(df):\n",
        "\n",
        "  if df['month'] in [12,1,2]:\n",
        "    return 'Winter'\n",
        "  elif df['month'] in [3,4,5]:\n",
        "    return 'Spring'\n",
        "  elif df['month'] in [6,7,8]:\n",
        "    return 'Summer'\n",
        "  elif df['month'] in [9,10,11]:\n",
        "    return 'Autumn'"
      ],
      "metadata": {
        "id": "f6Cf84BneiDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Season']=data.apply(get_season,axis=1)"
      ],
      "metadata": {
        "id": "1TkBKoOFfeal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_day_time(df):\n",
        "  if df['hour']>=6 and df['hour']<=18:\n",
        "    return 'Day'\n",
        "  else :\n",
        "    return 'Night'\n",
        "\n"
      ],
      "metadata": {
        "id": "7ijmgXdCg5AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['DateTime']=data.apply(get_day_time,axis=1)"
      ],
      "metadata": {
        "id": "ADWmU6VwDOUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oglnQNhjv73Q"
      },
      "outputs": [],
      "source": [
        "print(pd.DataFrame({\n",
        "    'Builndings Categories': data['primary_use'].unique()\n",
        "}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9msX3SS9MKr"
      },
      "outputs": [],
      "source": [
        "Elec_df = data.loc[data['meter'] == 0].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2A8_oiWyiYq"
      },
      "source": [
        "# Labeling the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "nRAAIsshsAam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOVrtfcLz7bX"
      },
      "outputs": [],
      "source": [
        "# Function to label encode categorical columns\n",
        "def label_encode_categoricals(df):\n",
        "    le = LabelEncoder()\n",
        "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    for col in categorical_cols:\n",
        "\n",
        "      df[col] = df[col].astype(str).str.lower()\n",
        "      df[col] = le.fit_transform(df[col])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply label encoding to categorical columns\n",
        "Elec_encode = label_encode_categoricals(Elec_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Elec_encode"
      ],
      "metadata": {
        "id": "r2L81lUG3AO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD9CeqOcZm29"
      },
      "outputs": [],
      "source": [
        "del Elec_df\n",
        "gc.collect();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's Visualise the data as Time Series"
      ],
      "metadata": {
        "id": "F1UG6HlMve2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "887B6dL22YbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lineplot_of_the_data(df):\n",
        "  df = df.sort_values(by='timestamp')\n",
        "\n",
        "\n",
        "  daily = df.groupby(['year','dayofyear'])['meter_reading'].sum().reset_index()\n",
        "\n",
        "  sns.lineplot(data=daily, x='dayofyear', y='meter_reading', hue='year')\n",
        "  plt.title(\"Daily Consumption by Year\")\n",
        "  plt.xlabel(\"Day of Year\")\n",
        "  plt.ylabel(\"Total Meter Reading\")\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lyzCuVyTvwIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lineplot_of_the_data(Elec_encode)"
      ],
      "metadata": {
        "id": "tXoSWpB62dTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning\n",
        "#Forecasting using Light GBM"
      ],
      "metadata": {
        "id": "JbxsUbt95s_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "QfOfmYLSrSIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid"
      ],
      "metadata": {
        "id": "zd9JDmN59OMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "def rmsle_metric(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred).clip(min=0)\n",
        "    return np.sqrt(mean_squared_error(np.log1p(y_true), np.log1p(y_pred)))\n",
        "\n",
        "def LGBM(data, params):\n",
        "    # Sort and create a daily datetime (keep for EVAL only)\n",
        "    data = data.sort_values('timestamp').copy()\n",
        "    data['date'] = pd.to_datetime(data['timestamp']).dt.floor('D')  # datetime64 (not object)\n",
        "\n",
        "    # IMPORTANT: don't pass 'date' to the model\n",
        "    X = data.drop(columns=['timestamp', 'meter_reading', 'date'])\n",
        "    y = data['meter_reading']\n",
        "\n",
        "    # Time-aware split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, train_size=0.85, shuffle=False\n",
        "    )\n",
        "\n",
        "    # Train on log target\n",
        "    y_train_log = np.log1p(y_train)\n",
        "    model = LGBMRegressor(verbosity=-1, **params)\n",
        "    model.fit(X_train, y_train_log)\n",
        "\n",
        "    # Predict and back-transform\n",
        "    y_pred = np.expm1(model.predict(X_test))\n",
        "\n",
        "    # Get the dates of the test rows from the original data by index\n",
        "    test_dates = data.loc[X_test.index, 'date']\n",
        "\n",
        "    # Build evaluation DataFrame\n",
        "    df_eval = pd.DataFrame({\n",
        "        'date': test_dates.values,\n",
        "        'y_true': y_test.values,\n",
        "        'y_pred': y_pred\n",
        "    })\n",
        "\n",
        "    # Aggregate to daily totals and sort chronologically\n",
        "    daily_true = df_eval.groupby('date')['y_true'].sum()\n",
        "    daily_pred = df_eval.groupby('date')['y_pred'].sum()\n",
        "\n",
        "    # Metrics on daily totals\n",
        "    rmse_score = np.sqrt(mean_squared_error(daily_true, daily_pred))\n",
        "    rmsle_score = rmsle_metric(daily_true, daily_pred)\n",
        "\n",
        "    print(f'Daily RMSE: {rmse_score:.3f}')\n",
        "    print(f'Daily RMSLE: {rmsle_score:.3f}')\n",
        "    return rmsle_score, rmse_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qRrLMSiourgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Grid search loop ----\n",
        "grid = {\n",
        "    'learning_rate': [0.05, 0.1, 1],\n",
        "    'max_depth': [5, 7],\n",
        "    'n_estimators': [200, 400],\n",
        "    'subsample': [0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9],\n",
        "    'min_child_samples': [20, 100],\n",
        "    'reg_lambda': [0.0, 0.1],\n",
        "    'reg_alpha': [0.0]\n",
        "}\n",
        "\n",
        "best = (float('inf'), None)\n",
        "for p in ParameterGrid(grid):\n",
        "    rmsle_score, rmse_score = LGBM(Elec_encode, p)\n",
        "    if rmsle_score < best[0]:\n",
        "        best = (rmsle_score, p)\n",
        "\n",
        "print(\"Best RMSLE:\", best[0])\n",
        "print(\"Best params:\", best[1])"
      ],
      "metadata": {
        "id": "F3oJFLZrRdtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_parameters = {\n",
        "    'learning_rate': 1,\n",
        "    'max_depth': 7,\n",
        "    'n_estimators': 200,\n",
        "    'subsample': 0.9,\n",
        "    'colsample_bytree': 0.9,\n",
        "    'reg_alpha': 0,\n",
        "    'reg_lambda': 0.1,\n",
        "    'min_child_samples': 20\n",
        "}"
      ],
      "metadata": {
        "id": "7iAMxrlZScTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsle_score, rmse_score = LGBM(Elec_encode, best_parameters)\n",
        "\n",
        "print(f'RMSLE: {rmsle_score: .4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1P_ZoxQRgJ6",
        "outputId": "3d071069-ac79-4adf-df7f-47a727d859a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daily RMSE: 352586.469\n",
            "Daily RMSLE: 0.061\n",
            "RMSLE:  0.0611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best RMSLE is ≈ 0.06"
      ],
      "metadata": {
        "id": "3MzwqN8dTB8p"
      }
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}